{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e28965",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5aa4c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# !pip install emoji\n",
    "import emoji\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01778ad",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ad5723eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_badminton = pd.read_csv(r\"reviews_badminton\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8b43b64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8518 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Reviewer Name               Review Title  \\\n",
       "0               Kamal Suresh               Nice product   \n",
       "1          Flipkart Customer     Don't waste your money   \n",
       "2     A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3        Suresh Narayanasamy                       Fair   \n",
       "4                  ASHIK P A                Over priced   \n",
       "...                      ...                        ...   \n",
       "8513                     NaN                        NaN   \n",
       "8514                     NaN                        NaN   \n",
       "8515                     NaN                        NaN   \n",
       "8516                     NaN                        NaN   \n",
       "8517                     NaN                        NaN   \n",
       "\n",
       "                  Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0      Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1      Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2     Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3        Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                             NaN     147.0        24.0  Apr 2016   \n",
       "...                           ...       ...         ...       ...   \n",
       "8513                          NaN       NaN         NaN       NaN   \n",
       "8514                          NaN       NaN         NaN       NaN   \n",
       "8515                          NaN       NaN         NaN       NaN   \n",
       "8516                          NaN       NaN         NaN       NaN   \n",
       "8517                          NaN       NaN         NaN       NaN   \n",
       "\n",
       "                                            Review text  Ratings  \n",
       "0     Nice product, good quality, but price is now r...        4  \n",
       "1     They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2     Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3     Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4     Over pricedJust â?¹620 ..from retailer.I didn'...        1  \n",
       "...                                                 ...      ...  \n",
       "8513                                                NaN        5  \n",
       "8514                                                NaN        2  \n",
       "8515                                                NaN        4  \n",
       "8516                                                NaN        1  \n",
       "8517                                                NaN        4  \n",
       "\n",
       "[8518 rows x 8 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_badminton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3e861b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8518, 8)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_badminton.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "adfa6121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Reviewer Name', 'Review Title', 'Place of Review', 'Up Votes',\n",
       "       'Down Votes', 'Month', 'Review text', 'Ratings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_badminton.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e63713a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8518 entries, 0 to 8517\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer Name    8508 non-null   object \n",
      " 1   Review Title     8508 non-null   object \n",
      " 2   Place of Review  8468 non-null   object \n",
      " 3   Up Votes         8508 non-null   float64\n",
      " 4   Down Votes       8508 non-null   float64\n",
      " 5   Month            8053 non-null   object \n",
      " 6   Review text      8510 non-null   object \n",
      " 7   Ratings          8518 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 532.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_badminton.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f692470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_badminton[\"Review\"] = df_badminton['Review Title'] + '. ' + df_badminton['Review text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "df816a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, 5, 2], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_badminton[\"Ratings\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0d665178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ratings\n",
       "5    0.596384\n",
       "4    0.204978\n",
       "1    0.090279\n",
       "3    0.072200\n",
       "2    0.036159\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_badminton[\"Ratings\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3a758f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Ratings'>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_badminton[\"Ratings\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3ca94ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the class labels \n",
    "df_badminton['Review_Type'] = df_badminton['Ratings'].apply(lambda x: 0 if (x<=3) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7ca7dadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice product. Nice product, good quality, but ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Don't waste your money. They didn't supplied Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did not meet expectations. Worst product. Dama...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fair. Quite O. K. , but nowadays  the quality ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Over priced. Over pricedJust â?¹620 ..from ret...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Review_Type\n",
       "0  Nice product. Nice product, good quality, but ...            1\n",
       "1  Don't waste your money. They didn't supplied Y...            0\n",
       "2  Did not meet expectations. Worst product. Dama...            0\n",
       "3  Fair. Quite O. K. , but nowadays  the quality ...            0\n",
       "4  Over priced. Over pricedJust â?¹620 ..from ret...            0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final useful columns \n",
    "df = df_badminton[[\"Review\", \"Review_Type\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "163a3c80-7300-4a84-8013-7cc2722203d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8518, 2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "50c1470e-bf20-4129-a84f-cf3071987598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d7af9cbf-b407-45cf-bd94-570761db5921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8508, 2)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "405d9f2e-8be6-4bfa-b3ad-9cc9e46f8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"sentiment_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b0ea2269-3828-4de3-845a-fc10df020fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8508, 2)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "660ac1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review         10\n",
       "Review_Type     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f3e6706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null value records\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4e27140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review         0\n",
       "Review_Type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "38421d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8508, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4816f09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review_Type\n",
       "1    6822\n",
       "0    1686\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for imbalance data\n",
    "df[\"Review_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67674484",
   "metadata": {},
   "source": [
    "# Identifying input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ef6f4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Review\"]\n",
    "y = df[\"Review_Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af091d",
   "metadata": {},
   "source": [
    "# Splitting into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f9f2b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "88d85358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95c07fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NAVYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\NAVYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\NAVYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ddbb58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialise the inbuilt Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "## We can also use Lemmatizer instead of Stemmer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0962d6",
   "metadata": {},
   "source": [
    "# Data Preprocessing on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "15dd6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(raw_text, flag):\n",
    "    # Removing special characters and digits\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "    \n",
    "    # change sentence to lower case\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    sentence = emoji.demojize(sentence).replace(':','')\n",
    "    \n",
    "    sentence = re.sub(r'<[^>]+','',sentence)\n",
    "    sentence = re.sub(r'[^a-zA-Z0-9 ]','',sentence)\n",
    "    sentence = re.sub(r'[0-9]','',sentence)\n",
    "    \n",
    "    # tokenize into words\n",
    "    tokens = sentence.split()\n",
    "\n",
    "    # remove stop words                \n",
    "    clean_tokens = [t for t in tokens if not t in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Stemming/Lemmatization\n",
    "    if(flag == 'stem'):\n",
    "        clean_tokens = [stemmer.stem(word) for word in clean_tokens]\n",
    "    else:\n",
    "        clean_tokens = [lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "    \n",
    "    return pd.Series([\" \".join(clean_tokens), len(clean_tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8c3074b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>classy product waste product ball worst pls ne...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>horrible good productread</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>yonex rock goodread</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>fabulous product delivered good within time th...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>terrific great experience buying yonex flipkar...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0   1\n",
       "6984  classy product waste product ball worst pls ne...  18\n",
       "7439                          horrible good productread   3\n",
       "7609                                yonex rock goodread   3\n",
       "2478  fabulous product delivered good within time th...   8\n",
       "7520  terrific great experience buying yonex flipkar...  10"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = X_train.apply(lambda x: text_preprocess(x, 'lemma'))\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ca5f2f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text_lemma</th>\n",
       "      <th>Text_length_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>classy product waste product ball worst pls ne...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>horrible good productread</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>yonex rock goodread</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>fabulous product delivered good within time th...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>terrific great experience buying yonex flipkar...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>pretty good genuine orginal productread</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>delightful badminton shuttle goodread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>wonderful best quality shuttle read</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>highly recommended nice happyread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>classy product good productread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6381 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_text_lemma  Text_length_lemma\n",
       "6984  classy product waste product ball worst pls ne...                 18\n",
       "7439                          horrible good productread                  3\n",
       "7609                                yonex rock goodread                  3\n",
       "2478  fabulous product delivered good within time th...                  8\n",
       "7520  terrific great experience buying yonex flipkar...                 10\n",
       "...                                                 ...                ...\n",
       "5734            pretty good genuine orginal productread                  5\n",
       "5191              delightful badminton shuttle goodread                  4\n",
       "5390                wonderful best quality shuttle read                  5\n",
       "860                   highly recommended nice happyread                  4\n",
       "7270                    classy product good productread                  4\n",
       "\n",
       "[6381 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.columns = ['clean_text_lemma', 'Text_length_lemma']\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d91af75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text_lemma</th>\n",
       "      <th>Text_length_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>classy product waste product ball worst pls ne...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>horrible good productread</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>yonex rock goodread</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>fabulous product delivered good within time th...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>terrific great experience buying yonex flipkar...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>pretty good genuine orginal productread</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>delightful badminton shuttle goodread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>wonderful best quality shuttle read</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>highly recommended nice happyread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>classy product good productread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6381 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_text_lemma  Text_length_lemma\n",
       "6984  classy product waste product ball worst pls ne...                 18\n",
       "7439                          horrible good productread                  3\n",
       "7609                                yonex rock goodread                  3\n",
       "2478  fabulous product delivered good within time th...                  8\n",
       "7520  terrific great experience buying yonex flipkar...                 10\n",
       "...                                                 ...                ...\n",
       "5734            pretty good genuine orginal productread                  5\n",
       "5191              delightful badminton shuttle goodread                  4\n",
       "5390                wonderful best quality shuttle read                  5\n",
       "860                   highly recommended nice happyread                  4\n",
       "7270                    classy product good productread                  4\n",
       "\n",
       "[6381 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean = pd.DataFrame(temp_df)\n",
    "X_train_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf335e2e",
   "metadata": {},
   "source": [
    "# Data preprocessing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3e9ab476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>awesome goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8422</th>\n",
       "      <td>classy product good product right app read</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>classy product good qualityread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>awesome goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>could way better thanksread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0  1\n",
       "4392                            awesome goodread  2\n",
       "8422  classy product good product right app read  7\n",
       "2138             classy product good qualityread  4\n",
       "3538                            awesome goodread  2\n",
       "2684                 could way better thanksread  4"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = X_test.apply(lambda x: text_preprocess(x, 'lemma'))\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "11139192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text_lemma</th>\n",
       "      <th>Text_length_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>awesome goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8422</th>\n",
       "      <td>classy product good product right app read</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>classy product good qualityread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>awesome goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>could way better thanksread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>nice product original oneread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>perfect product nice product indoors suitable ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>simply awesome supperread</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>excellent goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5953</th>\n",
       "      <td>unsatisfactory goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_text_lemma  Text_length_lemma\n",
       "4392                                   awesome goodread                  2\n",
       "8422         classy product good product right app read                  7\n",
       "2138                    classy product good qualityread                  4\n",
       "3538                                   awesome goodread                  2\n",
       "2684                        could way better thanksread                  4\n",
       "...                                                 ...                ...\n",
       "2516                      nice product original oneread                  4\n",
       "5309  perfect product nice product indoors suitable ...                  8\n",
       "2183                          simply awesome supperread                  3\n",
       "4362                                 excellent goodread                  2\n",
       "5953                            unsatisfactory goodread                  2\n",
       "\n",
       "[2127 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.columns = ['clean_text_lemma', 'Text_length_lemma']\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "124ae4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text_lemma</th>\n",
       "      <th>Text_length_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>awesome goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8422</th>\n",
       "      <td>classy product good product right app read</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>classy product good qualityread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>awesome goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>could way better thanksread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>nice product original oneread</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>perfect product nice product indoors suitable ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>simply awesome supperread</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>excellent goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5953</th>\n",
       "      <td>unsatisfactory goodread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_text_lemma  Text_length_lemma\n",
       "4392                                   awesome goodread                  2\n",
       "8422         classy product good product right app read                  7\n",
       "2138                    classy product good qualityread                  4\n",
       "3538                                   awesome goodread                  2\n",
       "2684                        could way better thanksread                  4\n",
       "...                                                 ...                ...\n",
       "2516                      nice product original oneread                  4\n",
       "5309  perfect product nice product indoors suitable ...                  8\n",
       "2183                          simply awesome supperread                  3\n",
       "4362                                 excellent goodread                  2\n",
       "5953                            unsatisfactory goodread                  2\n",
       "\n",
       "[2127 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_clean = pd.DataFrame(temp_df)\n",
    "X_test_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227ee48",
   "metadata": {},
   "source": [
    "# Pipeline for Optimal Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "07746b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from joblib import Memory\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b6a74b0-a28f-449b-a99b-e178d3c59204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/NAVYA/Downloads/MY_PYTHON_PRACTICE/Innomatics_internship/jup_vir_env/Scripts/ML_flow_Sentiment_analysis/mlruns/972715570874921247', creation_time=1711635366094, experiment_id='972715570874921247', last_update_time=1711635366094, lifecycle_stage='active', name='sentiment_analysis_prediction', tags={}>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"sentiment_analysis_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9739e044-f987-4bcd-a26e-18453e934dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 23:02:49 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "CPU times: total: 4.06 s\n",
      "Wall time: 11.4 s\n",
      "Test Score:  0.9245388485187256\n"
     ]
    }
   ],
   "source": [
    "pipelines = {'naive_bayes': Pipeline([\n",
    "        ('scaler', TfidfVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "     ])\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'naive_bayes': [\n",
    "        {\n",
    "            'scaler': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'scaler__max_features': [1000, 1500], \n",
    "            'scaler__alpha': [1]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipelines[\"naive_bayes\"], \n",
    "                           param_grid=param_grids[\"naive_bayes\"], \n",
    "                           cv=4, \n",
    "                           scoring='f1', \n",
    "                           return_train_score=True,\n",
    "                           verbose=1\n",
    "                          )\n",
    "\n",
    "# Fit the grid search\n",
    "with mlflow.start_run() as run:\n",
    "    %time grid_search.fit(X_train_clean[\"clean_text_lemma\"], y_train)\n",
    "\n",
    "# Access and print the test score\n",
    "print('Test Score: ', grid_search.score(X_test_clean[\"clean_text_lemma\"], y_test))\n",
    "\n",
    "best_models[algo] = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0756fde4-67eb-4071-a543-2766ff2192f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'knn' : Pipeline([\n",
    "        ('scaler', TfidfVectorizer()),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]), \n",
    "    'svc' : Pipeline([\n",
    "        ('scaler', TfidfVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ]),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('scaler', TfidfVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ]),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('scaler', TfidfVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'knn': [\n",
    "        {\n",
    "            'scaler': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'classifier__n_neighbors' : [i for i in range(3, 19, 2)], \n",
    "            'classifier__p' : [1, 2, 3]\n",
    "        }\n",
    "    ],\n",
    "    'svc': [\n",
    "        {\n",
    "            'scaler': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'classifier__kernel' : ['rbf'], \n",
    "            'classifier__C' : [0.1, 0.01, 1, 10, 100]\n",
    "        }, \n",
    "        {\n",
    "            'scaler': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'classifier__kernel' : ['poly'], \n",
    "            'classifier__degree' : [2, 3, 4, 5], \n",
    "            'classifier__C' : [0.1, 0.01, 1, 10, 100]\n",
    "        }, \n",
    "        {\n",
    "            'scaler': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'classifier__kernel' : ['linear'], \n",
    "            'classifier__C' : [0.1, 0.01, 1, 10, 100]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'scaler': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['l2']\n",
    "        }, \n",
    "        {\n",
    "            'scaler': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['l1'], \n",
    "            'classifier__solver': ['liblinear']\n",
    "        }, \n",
    "        {\n",
    "            'scaler': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['elasticnet'], \n",
    "            'classifier__l1_ratio': [0.4, 0.5, 0.6],\n",
    "            'classifier__solver': ['saga']\n",
    "        }\n",
    "    ],\n",
    "    'decision_tree': [\n",
    "        {\n",
    "            'scaler': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'classifier__max_depth': [None, 5, 8]\n",
    "        }\n",
    "    ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0a76a1c2-a6df-4681-be7c-334ec8e05e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** knn **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 23:04:56 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "CPU times: total: 4min 34s\n",
      "Wall time: 3min 29s\n",
      "Test Score:  0.9115829078204783\n",
      "\n",
      "********** svc **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 23:08:27 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 60 candidates, totalling 240 fits\n",
      "CPU times: total: 13min 7s\n",
      "Wall time: 13min 13s\n",
      "Test Score:  0.928787462194116\n",
      "\n",
      "********** logistic_regression **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 23:21:41 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "CPU times: total: 2min 33s\n",
      "Wall time: 2min 37s\n",
      "Test Score:  0.9289466408625933\n",
      "\n",
      "********** decision_tree **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 23:24:19 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "CPU times: total: 11.4 s\n",
      "Wall time: 18.7 s\n",
      "Test Score:  0.9171597633136095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=4, \n",
    "                               scoring='f1', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(X_train_clean[\"clean_text_lemma\"], y_train)\n",
    "    \n",
    "    # Access and print the test score\n",
    "    print('Test Score: ', grid_search.score(X_test_clean[\"clean_text_lemma\"], y_test))\n",
    "    \n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae58bd6-14b1-4af1-bd4b-d7c2e2a824cc",
   "metadata": {},
   "source": [
    "# Workflow Orchestration :Refactoring the ML Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f8748d7e-988b-47ba-85e2-7c32288fac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9f87b2a5-0335-444b-bc72-8d78f5757ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def split_inputs_output(data, inputs, output):\n",
    "    \"\"\"\n",
    "    Split features and target variables.\n",
    "    \"\"\"\n",
    "    X = data[inputs]\n",
    "    y = data[output]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def split_train_test(X, y, test_size=0.25, random_state=0):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "\n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Rescale the data.\n",
    "    \"\"\"\n",
    "    def clean_text(text):\n",
    "        # Remove \"READ MORE\"\n",
    "        text = re.sub(r'READ MORE', '', text)\n",
    "\n",
    "        # Remove numbers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "        # Remove punctuation marks\n",
    "        text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
    "\n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # Lemmatize words to their base form\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "        # Join tokens back into a single string\n",
    "        cleaned_text = ' '.join(tokens)\n",
    "\n",
    "        return cleaned_text\n",
    "\n",
    "    for col in X_train.columns:\n",
    "        X_train[col] = X_train[col].apply(lambda doc: clean_text(doc))\n",
    "    for col in X_test.columns:\n",
    "        X_test[col] = X_test[col].apply(lambda doc: clean_text(doc))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, hyperparameters):\n",
    "    \"\"\"\n",
    "    Training the machine learning model.\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text_1', TfidfVectorizer(), 'Review'),  # TF-IDF vectorization for text_data_1   \n",
    "        ],\n",
    "        remainder='passthrough'  # Keep other columns unchanged\n",
    "    )\n",
    "    clf = Pipeline(\n",
    "        [\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', LogisticRegression(**hyperparameters))\n",
    "        ]\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluating the model.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_score = metrics.f1_score(y_train, y_train_pred)\n",
    "    test_score = metrics.f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score\n",
    "\n",
    "\n",
    "def workflow():\n",
    "    DATA_PATH = \"sentiment_data.csv\"\n",
    "    INPUTS = ['Review']\n",
    "    OUTPUT = 'Review_Type'\n",
    "    HYPERPARAMETERS = {'C': 1, 'penalty': \"l2\"}\n",
    "    \n",
    "    # Load data\n",
    "    data = load_data(DATA_PATH)\n",
    "    \n",
    "    # Identify Inputs and Output\n",
    "    X, y = split_inputs_output(data, INPUTS, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "\n",
    "    # Preprocess the data\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Build a model\n",
    "    model = train_model(X_train, y_train, HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "831ddba1-4318-4409-bace-b2e0dec90357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9325686800480991\n",
      "Test Score: 0.9181614349775785\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "67c46c54-4aba-4de8-ac56-2aae93fdd577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
